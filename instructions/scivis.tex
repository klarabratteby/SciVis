\documentclass{labinstructions}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{enumitem}
\usepackage[mathcal]{eucal}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{times}

\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan}

\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}

\begin{document}

\setcounter{page}{1}

\pagestyle{empty}


%
% Title
%
\begin{center}
{\Huge TNM093 2021 --- SciVis Mini-Project}
\vspace{0.6cm}

\Large{Project examiner/assistants: Alexander Bock, Emma Broman, Emma Nilsson}
\end{center}

\title{TMN093 Mini-project --- Scientific Visualization}
\author{Alexander Bock}
\date{November 2020}

\pagestyle{fancy}
\fancyfoot[c]{}
\fancyfoot[R]{\thepage}

\section{Intended Learning Outcomes}
The goal of this mini-project is to provide an improved and practical familiarity with the concept of volume rendering.  This includes understanding of the raycasting steps, the application of composition methods, the generation of transfer functions, and the ability to analyse a dataset interactively.  These techniques should be implemented in a framework that does not require much overhead and is easily extensible to be able to focus on these individual goals, rather than requiring the development of an end-to-end solution.

The student shall, after finishing this mini-project, be able to:
\begin{itemize}
  \item qualitatively understand the visualization technique of direct volume rendering,
  \item in detail understand three of the composition techniques (front-to-back, first hit point, maximum intensity projection) and possess the ability to reason about interesting new composition methods
  \item comprehend the concept of a transfer function in volume exploration and have the ability to design and implement an editor for manipulating the transfer function interactively to aid exploration
  \item be able to implement these techniques with web technologies such as JavaScript, WebGL2, and, for the transfer function, using any other libraries as determined by the student.
\end{itemize}{}



\section{The Environment}
For this mini-project, a simple JavaScript + WebGL environment is provided that should be used as the starting point for the implementation.  The framework, including the data, can be found in the Lisam course page or at \href{http://weber.itn.liu.se/~alebo68/lectures/tnm093/2020/scivis-miniproject.zip}{http://weber.itn.liu.se/~alebo68/lectures/tnm093/2020/scivis-miniproject.zip}.  The code alone can also be found as a GitHub template at \href{https://github.com/alexanderbock/TNM093}{https://github.com/alexanderbock/TNM093}.

The environment contains code that creates a WebGL window on the webpage, loads a dataset, renders the entry/exit bounding boxes, and initiates the volume rendering.  It uses a simple, predefined transfer function to show initial results.  As it requires WebGL2, the browser that you are using to view the webpage has to support the WebGL2 feature.  This should be the case for most modern browsers, but if in doubt, check \href{https://caniuse.com/\#feat=webgl2}{https://caniuse.com/\#feat=webgl2} for the different version when WebGL2 was supported for the different browser vendors.  Particularly Safari on MacOS does \emph{not} implement this feature and we'd recommend Firefox or Chrome on that operating system.

The environment has a number of rendering parameter that can be changed.  The step size between samples along the different rays can be changed interactively, the compositing methods can be changed using radio buttons, the camera can be moved around the volume, and the output rendering can be changed for debugging purposes and can show the volume rendering, the entry or exit points, the ray direction, the currently employed transfer function, or show a single slice of the volume.

\textbf{Important}: The environment requires two external files to be served locally, which means that just opening the webpage will \emph{not} work and only produce an empty white rendering and an error message in the browser log.  You will need to host a webserver and then go to the address of that webserver to see the rendering and work with it.  The recommended way is to use Python for a simple webhosting service by executing: \texttt{python -m http.server} in the folder where the \texttt{index.html}, \texttt{gl-matrix.js}, and \texttt{pig.raw} files are located.  This directory will then be served and be accessibly by visiting \href{http://localhost:8000}{http://localhost:8000} on your machine.  It is also possible to host the files on any other webserver and use them from there, but be aware that the \texttt{pig.raw} file is 70\,MiB in size and will be downloaded again and again everytime you refresh the page.  Waiting for the delivery of the file from the internet will consume quite some time.


\section{The Tasks}
\begin{itemize}
  \item Familiarize yourself with the provided framework and conceptually understand everything that is happening in the initialization and the rendering loop before starting to implement anything.
  \item Implement the front-to-back compositing, first hit points, and maximum intensity projection compositing methods in the volume rendering \texttt{traverseRay} function.
  \item Using whichever techniques you want, implement a way to interactively update the transfer function to change the results of the volume rendering by manipulating the way the volume samples are mapped to color + transparency.  It is recommended to stick to either a widget-based or node-based transfer function editor as shown in the lecture and not implement multiple methods.  See the checklist below for a more detailed list of requirements.  The transfer function is updated in the \texttt{updateTransferFunction} function.  \textbf{Important}:  Don't forget to call the \texttt{triggerTransferFunctionUpdate} function after anything has changed in your transfer function editor or otherwise the rendering will not be notified of your new transfer function.
\end{itemize}

The following is a Todo list that needs to be completed with a lab assistant to have successfully passed the lab.  \textbf{Important}:  The amount of time required for this mini-project is \emph{much} more than what is allotted in the lab sessions.  There are 8\,h of lab sessions per group, but the mini-project is scheduled for 48\,h of work in total.  If you only implement things while being in the lab itself, you will \emph{not} be able to finish the project.

Please note: If some time has passed between finishing the project and showing it to the lab assistants, take some time to refamiliarize yourself with the code you have written before calling them over.  ``I don't remember, this has been a while'' is \emph{not} a good answer to any of the questions below.
\begin{todolist}
  \item Read the \emph{entire} instructions carefully
  \item Interact with the camera controls and explain what the step size does and how volume rendering works and how you get a color for a pixel.  For this explanation you can assume that you already have an entry and an exit point, there is no need to explain anything prior to that.  Do this on a piece of paper by drawing a sketch.
  \item Show that the front-to-back compositing method works, show the implementation, and conceptually explain how it works
  \item Show that the first hit-point compositing method works, show the implementation, and explain how this compositing method works
  \item Show that the maximum intensity projection compositing method works, show the implementation, and explain how this works
  \item Using the front-to-back compositing method, use your transfer function editor to interactively manipulate the transfer function to show the lab assisstant what is on the inside of the dataset.  Your editor must be capable of the following:
  \begin{todolist}
    \item Have a single transfer function editor
    \item Change the transfer function without needing to reload the webpage
    \item Have the ability to change the color and opacity mapping for volume samples
    \item Be able to interact with the editor and change the transfer function settings with the mouse
    \item Have the ability to simulate isosurface rendering by being able to create ``spiky'' transfer functions that have a high opacity only for a few values with different colors.
  \end{todolist}
  \item Write a one-page summary documenting your findings while interacting with your transfer function widget, what you have learned from this lab, and what findings were unexpected.  Add the descriptions for the front-to-back, first hit-point, and maximum intensity projection composition methods.  Add a short reflection about the situations in which to prefer InfoVis and SciVis visualization methods. 
\end{todolist}

\end{document}
